{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea09ad0",
   "metadata": {},
   "source": [
    "# Knowledge Graph Construction with Neo4j and Local Embeddings\n",
    "\n",
    "This notebook constructs a semantic knowledge graph from user interest data using Neo4j as the graph database and sentence-transformers for local embeddings. The knowledge graph captures relationships between semantic categories, topics, entities, and search clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c6989",
   "metadata": {},
   "source": [
    "## 1. Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d75aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All dependencies installed successfully\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install required packages\n",
    "packages = [\n",
    "    'neo4j',\n",
    "    'sentence-transformers',\n",
    "    'pandas',\n",
    "    'numpy',\n",
    "    'networkx',\n",
    "    'matplotlib',\n",
    "    'scikit-learn',\n",
    "    'tqdm'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
    "\n",
    "print(\"✓ All dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5a212f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Neo4j imports\n",
    "from neo4j import GraphDatabase, basic_auth\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "\n",
    "# Embedding and ML imports\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd5442",
   "metadata": {},
   "source": [
    "## 1.5 Docker Commands for Neo4j\n",
    "\n",
    "Before connecting to Neo4j, ensure the Docker container is running. Use these commands to manage the Neo4j container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e664e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Neo4j logs\n",
    "!docker logs neo4j --tail 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Neo4j container (this will delete all data)\n",
    "!docker stop neo4j\n",
    "!docker rm neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Neo4j container\n",
    "!docker stop neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start existing Neo4j container (if already created but stopped)\n",
    "!docker start fabric-kg\n",
    "\n",
    "print(\"⏳ Waiting for Neo4j to start...\")\n",
    "import time\n",
    "time.sleep(10)\n",
    "print(\"✓ Neo4j started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2278e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Neo4j container with increased memory settings\n",
    "!docker run -d \\\n",
    "  --name fabric-kg \\\n",
    "  -p 7687:7687 \\\n",
    "  -p 7474:7474 \\\n",
    "  -e NEO4J_AUTH=neo4j/password \\\n",
    "  -e NEO4J_dbms_memory_heap_initial__size=2G \\\n",
    "  -e NEO4J_dbms_memory_heap_max__size=2G \\\n",
    "  -e NEO4J_dbms_memory_pagecache_size=1G \\\n",
    "  neo4j:latest\n",
    "\n",
    "print(\"⏳ Waiting 20-30 seconds for Neo4j to fully start...\")\n",
    "import time\n",
    "time.sleep(25)\n",
    "print(\"✓ Neo4j should be ready now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df11b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Neo4j container is running\n",
    "!docker ps | grep neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa6e32",
   "metadata": {},
   "source": [
    "### Access Neo4j Browser\n",
    "\n",
    "Once the container is running, you can access the Neo4j Browser interface at:\n",
    "\n",
    "**http://localhost:7474**\n",
    "\n",
    "Login credentials:\n",
    "- Username: `neo4j`\n",
    "- Password: `password`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380d9766",
   "metadata": {},
   "source": [
    "## 2. Initialize Neo4j Connection\n",
    "\n",
    "Configure and establish connection to a local Neo4j database instance. Make sure Neo4j is running locally (typically on `bolt://localhost:7687` for default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe430284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j Configuration\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"password\"  # Default password for fresh Neo4j\n",
    "\n",
    "class Neo4jConnection:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = None\n",
    "        try:\n",
    "            self.driver = GraphDatabase.driver(uri, auth=basic_auth(user, password))\n",
    "            # Test connection\n",
    "            with self.driver.session() as session:\n",
    "                result = session.run(\"RETURN 1\")\n",
    "                print(\"✓ Successfully connected to Neo4j\")\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            if \"credentials expired\" in error_msg.lower():\n",
    "                print(\"⚠ Neo4j credentials expired. Attempting to update password...\")\n",
    "                try:\n",
    "                    # Try with initial password\n",
    "                    temp_driver = GraphDatabase.driver(uri, auth=basic_auth(user, \"neo4j\"))\n",
    "                    with temp_driver.session() as temp_session:\n",
    "                        temp_session.run(f\"ALTER CURRENT USER SET PASSWORD FROM 'neo4j' TO '{password}'\")\n",
    "                    temp_driver.close()\n",
    "                    # Now try with new password\n",
    "                    self.driver = GraphDatabase.driver(uri, auth=basic_auth(user, password))\n",
    "                    with self.driver.session() as session:\n",
    "                        session.run(\"RETURN 1\")\n",
    "                    print(\"✓ Successfully updated credentials and connected to Neo4j\")\n",
    "                except Exception as pwd_error:\n",
    "                    print(f\"✗ Failed to update password: {pwd_error}\")\n",
    "                    raise\n",
    "            elif \"ServiceUnavailable\" in str(type(e)):\n",
    "                print(\"✗ Neo4j service unavailable at\", uri)\n",
    "                print(\"  Make sure Neo4j is running. You can start it with:\")\n",
    "                print(\"  - Docker: docker run -it --rm -p 7687:7687 -v data:/data neo4j\")\n",
    "                raise\n",
    "            else:\n",
    "                print(f\"✗ Connection error: {e}\")\n",
    "                raise\n",
    "    \n",
    "    def close(self):\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "    \n",
    "    def query(self, query_str, **kwargs):\n",
    "        with self.driver.session() as session:\n",
    "            return session.run(query_str, **kwargs).data()\n",
    "\n",
    "# Initialize connection (handle connection errors gracefully)\n",
    "try:\n",
    "    neo4j_conn = Neo4jConnection(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")\n",
    "    neo4j_conn = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113b42b",
   "metadata": {},
   "source": [
    "## 3. Load Both Data Sources\n",
    "\n",
    "Load both the user interests data and website extraction cache to build a unified knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc150d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== USER INTERESTS DATA ===\n",
      "✓ Data loaded successfully\n",
      "  - Total activities: 53031\n",
      "  - Total searches: 30535\n",
      "  - Total page visits: 22496\n",
      "  - Semantic categories: 10\n",
      "  - Top entities: 20\n",
      "\n",
      "=== WEBSITE EXTRACTION DATA ===\n",
      "✓ Data loaded successfully\n",
      "  - Total websites: 19791\n"
     ]
    }
   ],
   "source": [
    "# Load user interest data\n",
    "json_file_path = Path(\"structured_user_interests.json\")\n",
    "if not json_file_path.exists():\n",
    "    json_file_path = Path(\"/Users/shreyasjagannath/dev/fabric/onfabric-data-science-interview/structured_user_interests_v1.json\")\n",
    "\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    user_data = json.load(f)\n",
    "\n",
    "print(\"=== USER INTERESTS DATA ===\")\n",
    "print(f\"✓ Data loaded successfully\")\n",
    "print(f\"  - Total activities: {user_data['metadata']['total_activities']}\")\n",
    "print(f\"  - Total searches: {user_data['metadata']['total_searches']}\")\n",
    "print(f\"  - Total page visits: {user_data['metadata']['total_page_visits']}\")\n",
    "print(f\"  - Semantic categories: {len(user_data['semantic_categories'])}\")\n",
    "print(f\"  - Top entities: {len(user_data['top_entities'])}\")\n",
    "\n",
    "# Load website extraction cache\n",
    "cache_file = Path(\"openai_extraction_cache.json\")\n",
    "if not cache_file.exists():\n",
    "    cache_file = Path(\"/Users/shreyasjagannath/dev/fabric/onfabric-data-science-interview/openai_extraction_cache_latest.json\")\n",
    "\n",
    "with open(cache_file, 'r', encoding='utf-8') as f:\n",
    "    website_cache = json.load(f)\n",
    "\n",
    "print(f\"\\n=== WEBSITE EXTRACTION DATA ===\")\n",
    "print(f\"✓ Data loaded successfully\")\n",
    "print(f\"  - Total websites: {len(website_cache)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f2255",
   "metadata": {},
   "source": [
    "## 4. Setup Local Embedding Model\n",
    "\n",
    "Initialize sentence-transformers for local embeddings. Using `all-MiniLM-L6-v2` (lightweight, ~90MB) for efficient local processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33deb138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model... (this may take a moment on first run)\n",
      "✓ Model loaded: 384-dimensional embeddings\n",
      "✓ Test embedding generated: shape (384,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model\n",
    "print(\"Loading embedding model... (this may take a moment on first run)\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"✓ Model loaded: {embedding_model.get_sentence_embedding_dimension()}-dimensional embeddings\")\n",
    "\n",
    "# Embedding function\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generate embedding for a text string\"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return None\n",
    "    try:\n",
    "        # Clean text\n",
    "        clean_text = text.strip()[:512]  # Truncate to 512 chars\n",
    "        embedding = embedding_model.encode(clean_text)\n",
    "        return embedding.tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"Error embedding text: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test embedding\n",
    "test_embedding = get_embedding(\"Technology and innovation\")\n",
    "print(f\"✓ Test embedding generated: shape {np.array(test_embedding).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0605e370",
   "metadata": {},
   "source": [
    "## 5. Create Unified Knowledge Graph Schema\n",
    "\n",
    "Define a unified schema with common node types:\n",
    "- **Category**: All categories (from both sources)\n",
    "- **Topic**: All topics (from both sources)  \n",
    "- **Entity**: All entities/items (from both sources)\n",
    "- **Website**: Visited websites\n",
    "- **User**: The user node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "if neo4j_conn:\n",
    "    # Clear existing data\n",
    "    print(\"Clearing existing graph data...\")\n",
    "    try:\n",
    "        neo4j_conn.query(\"MATCH (n) DETACH DELETE n\")\n",
    "        print(\"✓ Existing data cleared\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: {e}\")\n",
    "    \n",
    "    # Create constraints for unified schema\n",
    "    print(\"Creating constraints...\")\n",
    "    constraints = [\n",
    "        \"CREATE CONSTRAINT category_name IF NOT EXISTS FOR (c:Category) REQUIRE c.name IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT topic_id IF NOT EXISTS FOR (t:Topic) REQUIRE t.topic_id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:Entity) REQUIRE e.entity_id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT user_id IF NOT EXISTS FOR (u:User) REQUIRE u.user_id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT website_domain IF NOT EXISTS FOR (w:Website) REQUIRE w.domain IS UNIQUE\",\n",
    "    ]\n",
    "    \n",
    "    for constraint in constraints:\n",
    "        try:\n",
    "            neo4j_conn.query(constraint)\n",
    "        except Exception as e:\n",
    "            pass  # Constraint may already exist\n",
    "    \n",
    "    print(\"✓ Schema constraints created\")\n",
    "    print(\"\\n=== UNIFIED SCHEMA ===\")\n",
    "    print(\"Node Types:\")\n",
    "    print(\"  - Category: All categories from both data sources\")\n",
    "    print(\"  - Topic: All topics from both data sources\")\n",
    "    print(\"  - Entity: All entities/items from both data sources\")\n",
    "    print(\"  - Website: Visited websites\")\n",
    "    print(\"  - User: User profile\")\n",
    "    print(\"\\nRelationship Types:\")\n",
    "    print(\"  - (Topic)-[:BELONGS_TO]->(Category)\")\n",
    "    print(\"  - (Topic)-[:MENTIONS]->(Entity)\")\n",
    "    print(\"  - (User)-[:INTERESTED_IN]->(Topic)\")\n",
    "    print(\"  - (User)-[:VISITED]->(Website)\")\n",
    "    print(\"  - (Website)-[:HAS_CATEGORY]->(Category)\")\n",
    "    print(\"  - (Website)-[:HAS_TOPIC]->(Topic)\")\n",
    "    print(\"  - (Website)-[:MENTIONS]->(Entity)\")\n",
    "else:\n",
    "    print(\"✗ Cannot create schema: Neo4j connection not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260d04e",
   "metadata": {},
   "source": [
    "## 6. Extract and Unify Data from Both Sources\n",
    "\n",
    "Extract categories, topics, and entities from both data sources into unified dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    if isinstance(text, (list, dict)):\n",
    "        return str(text)[:256]\n",
    "    text = ' '.join(str(text).split())\n",
    "    return text[:256]\n",
    "\n",
    "def extract_url_domain(text):\n",
    "    \"\"\"Extract domain from URL\"\"\"\n",
    "    match = re.search(r'https?://([^/]+)', text)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def make_id(text):\n",
    "    \"\"\"Create a clean ID from text\"\"\"\n",
    "    return text.lower().replace(' ', '_').replace('-', '_')[:100]\n",
    "\n",
    "print(\"=== EXTRACTING DATA FROM BOTH SOURCES ===\\n\")\n",
    "\n",
    "# Unified dictionaries\n",
    "all_categories = {}  # category_name -> {name, source, count}\n",
    "all_topics = {}      # topic_id -> {id, content, category, source, website}\n",
    "all_entities = {}    # entity_id -> {id, name, type, source, count}\n",
    "all_websites = {}    # domain -> {domain, url, category, topic, items}\n",
    "\n",
    "# ============ PROCESS USER INTERESTS DATA ============\n",
    "print(\"Processing user interests data...\")\n",
    "\n",
    "# Extract categories from user interests\n",
    "for category_name, category_data in user_data['semantic_categories'].items():\n",
    "    cat_id = make_id(category_name)\n",
    "    all_categories[cat_id] = {\n",
    "        'id': cat_id,\n",
    "        'name': category_name,\n",
    "        'source': 'user_interests',\n",
    "        'activity_count': category_data.get('activity_count', 0),\n",
    "        'search_count': category_data.get('search_count', 0)\n",
    "    }\n",
    "    \n",
    "    # Extract topics from this category\n",
    "    for topic_text in category_data.get('topics', []):\n",
    "        if not topic_text or not isinstance(topic_text, str) or len(topic_text) < 5:\n",
    "            continue\n",
    "        \n",
    "        topic_text = clean_text(topic_text)\n",
    "        topic_id = f\"user_{make_id(topic_text[:50])}_{len(all_topics)}\"\n",
    "        \n",
    "        all_topics[topic_id] = {\n",
    "            'id': topic_id,\n",
    "            'content': topic_text,\n",
    "            'category': category_name,\n",
    "            'source': 'user_interests',\n",
    "            'is_url': 'http' in topic_text.lower()\n",
    "        }\n",
    "\n",
    "# Extract entities from user interests\n",
    "for entity_name, mention_count in user_data['top_entities'].items():\n",
    "    entity_id = make_id(entity_name)\n",
    "    if entity_id not in all_entities:\n",
    "        all_entities[entity_id] = {\n",
    "            'id': entity_id,\n",
    "            'name': entity_name,\n",
    "            'source': 'user_interests',\n",
    "            'mention_count': mention_count,\n",
    "            'entity_type': 'named_entity'\n",
    "        }\n",
    "\n",
    "print(f\"  ✓ Categories: {len([c for c in all_categories.values() if c['source'] == 'user_interests'])}\")\n",
    "print(f\"  ✓ Topics: {len([t for t in all_topics.values() if t['source'] == 'user_interests'])}\")\n",
    "print(f\"  ✓ Entities: {len([e for e in all_entities.values() if e['source'] == 'user_interests'])}\")\n",
    "\n",
    "# ============ PROCESS WEBSITE EXTRACTION DATA ============\n",
    "print(\"\\nProcessing website extraction data...\")\n",
    "\n",
    "for cache_key, extraction_data in website_cache.items():\n",
    "    # Extract URL from cache key\n",
    "    url = None\n",
    "    if 'Website:' in cache_key:\n",
    "        url = cache_key.split('Website: ')[1].split('\\\\nContent')[0].strip()\n",
    "    \n",
    "    if not url:\n",
    "        continue\n",
    "    \n",
    "    domain = extract_url_domain(url) or url\n",
    "    category_name = extraction_data.get('category', 'Uncategorized')\n",
    "    topic_text = extraction_data.get('topic', '')\n",
    "    items = extraction_data.get('items', [])\n",
    "    \n",
    "    # Store website\n",
    "    all_websites[domain] = {\n",
    "        'domain': domain,\n",
    "        'url': url,\n",
    "        'category': category_name,\n",
    "        'topic': topic_text,\n",
    "        'items': items\n",
    "    }\n",
    "    \n",
    "    # Add category if not exists\n",
    "    cat_id = make_id(category_name)\n",
    "    if cat_id not in all_categories:\n",
    "        all_categories[cat_id] = {\n",
    "            'id': cat_id,\n",
    "            'name': category_name,\n",
    "            'source': 'website_extraction',\n",
    "            'activity_count': 0,\n",
    "            'search_count': 0\n",
    "        }\n",
    "    \n",
    "    # Add topic\n",
    "    if topic_text and len(topic_text) > 2:\n",
    "        topic_id = f\"web_{make_id(topic_text[:50])}_{len(all_topics)}\"\n",
    "        all_topics[topic_id] = {\n",
    "            'id': topic_id,\n",
    "            'content': topic_text,\n",
    "            'category': category_name,\n",
    "            'source': 'website_extraction',\n",
    "            'website': domain,\n",
    "            'is_url': False\n",
    "        }\n",
    "    \n",
    "    # Add entities/items\n",
    "    for item in items:\n",
    "        if item and isinstance(item, str):\n",
    "            entity_id = make_id(item)\n",
    "            if entity_id not in all_entities:\n",
    "                all_entities[entity_id] = {\n",
    "                    'id': entity_id,\n",
    "                    'name': item,\n",
    "                    'source': 'website_extraction',\n",
    "                    'mention_count': 1,\n",
    "                    'entity_type': 'extracted_item'\n",
    "                }\n",
    "            else:\n",
    "                # Increment count if already exists\n",
    "                all_entities[entity_id]['mention_count'] = all_entities[entity_id].get('mention_count', 0) + 1\n",
    "\n",
    "print(f\"  ✓ Websites: {len(all_websites)}\")\n",
    "print(f\"  ✓ New Categories: {len([c for c in all_categories.values() if c['source'] == 'website_extraction'])}\")\n",
    "print(f\"  ✓ New Topics: {len([t for t in all_topics.values() if t['source'] == 'website_extraction'])}\")\n",
    "print(f\"  ✓ New Entities: {len([e for e in all_entities.values() if e['source'] == 'website_extraction'])}\")\n",
    "\n",
    "print(f\"\\n=== TOTAL UNIFIED DATA ===\")\n",
    "print(f\"  • Total Categories: {len(all_categories)}\")\n",
    "print(f\"  • Total Topics: {len(all_topics)}\")\n",
    "print(f\"  • Total Entities: {len(all_entities)}\")\n",
    "print(f\"  • Total Websites: {len(all_websites)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69798d61",
   "metadata": {},
   "source": [
    "## 7. Generate Embeddings for All Nodes\n",
    "\n",
    "Generate vector embeddings for all categories, topics, and entities from both data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating embeddings for all nodes...\")\n",
    "\n",
    "# Generate embeddings for categories\n",
    "print(\"  - Embedding categories...\")\n",
    "for cat_id in tqdm(all_categories.keys()):\n",
    "    text = all_categories[cat_id]['name']\n",
    "    all_categories[cat_id]['embedding'] = get_embedding(text)\n",
    "\n",
    "# Generate embeddings for topics\n",
    "print(\"  - Embedding topics...\")\n",
    "for topic_id in tqdm(all_topics.keys()):\n",
    "    text = all_topics[topic_id]['content']\n",
    "    all_topics[topic_id]['embedding'] = get_embedding(text)\n",
    "\n",
    "# Generate embeddings for entities\n",
    "print(\"  - Embedding entities...\")\n",
    "for entity_id in tqdm(all_entities.keys()):\n",
    "    text = all_entities[entity_id]['name']\n",
    "    all_entities[entity_id]['embedding'] = get_embedding(text)\n",
    "\n",
    "print(\"\\n✓ Embeddings generated successfully\")\n",
    "print(f\"  - Embedding dimension: 384\")\n",
    "print(f\"  - Categories with embeddings: {len(all_categories)}\")\n",
    "print(f\"  - Topics with embeddings: {len(all_topics)}\")\n",
    "print(f\"  - Entities with embeddings: {len(all_entities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ca2863",
   "metadata": {},
   "source": [
    "## 8. Populate Neo4j with Unified Knowledge Graph\n",
    "\n",
    "Create all nodes and relationships in Neo4j using the unified schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "if neo4j_conn:\n",
    "    print(\"Populating Neo4j with unified knowledge graph...\")\n",
    "    \n",
    "    # Create User node\n",
    "    print(\"\\n1. Creating User node...\")\n",
    "    user_query = \"\"\"\n",
    "    CREATE (u:User {\n",
    "        user_id: 'user_001',\n",
    "        total_activities: $total_activities,\n",
    "        total_searches: $total_searches,\n",
    "        total_page_visits: $total_page_visits,\n",
    "        created_at: datetime()\n",
    "    })\n",
    "    \"\"\"\n",
    "    neo4j_conn.query(user_query, \n",
    "        total_activities=user_data['metadata']['total_activities'],\n",
    "        total_searches=user_data['metadata']['total_searches'],\n",
    "        total_page_visits=user_data['metadata']['total_page_visits']\n",
    "    )\n",
    "    print(\"  ✓ User node created\")\n",
    "    \n",
    "    # Create Category nodes\n",
    "    print(\"\\n2. Creating Category nodes...\")\n",
    "    for cat_id, cat_data in tqdm(all_categories.items(), desc=\"Categories\"):\n",
    "        cat_query = \"\"\"\n",
    "        CREATE (c:Category {\n",
    "            category_id: $category_id,\n",
    "            name: $name,\n",
    "            source: $source,\n",
    "            activity_count: $activity_count,\n",
    "            search_count: $search_count,\n",
    "            embedding: $embedding\n",
    "        })\n",
    "        \"\"\"\n",
    "        neo4j_conn.query(cat_query,\n",
    "            category_id=cat_data['id'],\n",
    "            name=cat_data['name'],\n",
    "            source=cat_data['source'],\n",
    "            activity_count=cat_data.get('activity_count', 0),\n",
    "            search_count=cat_data.get('search_count', 0),\n",
    "            embedding=cat_data['embedding']\n",
    "        )\n",
    "    print(f\"  ✓ Created {len(all_categories)} Category nodes\")\n",
    "    \n",
    "    # Create Entity nodes\n",
    "    print(\"\\n3. Creating Entity nodes...\")\n",
    "    for entity_id, entity_data in tqdm(all_entities.items(), desc=\"Entities\"):\n",
    "        entity_query = \"\"\"\n",
    "        CREATE (e:Entity {\n",
    "            entity_id: $entity_id,\n",
    "            name: $name,\n",
    "            source: $source,\n",
    "            entity_type: $entity_type,\n",
    "            mention_count: $mention_count,\n",
    "            embedding: $embedding\n",
    "        })\n",
    "        \"\"\"\n",
    "        neo4j_conn.query(entity_query,\n",
    "            entity_id=entity_data['id'],\n",
    "            name=entity_data['name'],\n",
    "            source=entity_data['source'],\n",
    "            entity_type=entity_data.get('entity_type', 'unknown'),\n",
    "            mention_count=entity_data.get('mention_count', 1),\n",
    "            embedding=entity_data['embedding']\n",
    "        )\n",
    "    print(f\"  ✓ Created {len(all_entities)} Entity nodes\")\n",
    "    \n",
    "    # Create Topic nodes with relationships\n",
    "    print(\"\\n4. Creating Topic nodes and relationships...\")\n",
    "    for topic_id, topic_data in tqdm(all_topics.items(), desc=\"Topics\"):\n",
    "        # Create Topic node\n",
    "        topic_query = \"\"\"\n",
    "        CREATE (t:Topic {\n",
    "            topic_id: $topic_id,\n",
    "            content: $content,\n",
    "            source: $source,\n",
    "            is_url: $is_url,\n",
    "            embedding: $embedding\n",
    "        })\n",
    "        \"\"\"\n",
    "        neo4j_conn.query(topic_query,\n",
    "            topic_id=topic_data['id'],\n",
    "            content=topic_data['content'],\n",
    "            source=topic_data['source'],\n",
    "            is_url=topic_data.get('is_url', False),\n",
    "            embedding=topic_data['embedding']\n",
    "        )\n",
    "        \n",
    "        # Link Topic to Category\n",
    "        cat_name = topic_data['category']\n",
    "        cat_id = make_id(cat_name)\n",
    "        topic_to_category = \"\"\"\n",
    "        MATCH (t:Topic {topic_id: $topic_id})\n",
    "        MATCH (c:Category {category_id: $category_id})\n",
    "        CREATE (t)-[:BELONGS_TO]->(c)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            neo4j_conn.query(topic_to_category, topic_id=topic_data['id'], category_id=cat_id)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Link User to Topic (for user interest topics)\n",
    "        if topic_data['source'] == 'user_interests':\n",
    "            user_to_topic = \"\"\"\n",
    "            MATCH (u:User {user_id: 'user_001'})\n",
    "            MATCH (t:Topic {topic_id: $topic_id})\n",
    "            CREATE (u)-[:INTERESTED_IN]->(t)\n",
    "            \"\"\"\n",
    "            try:\n",
    "                neo4j_conn.query(user_to_topic, topic_id=topic_data['id'])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"  ✓ Created {len(all_topics)} Topic nodes with relationships\")\n",
    "    \n",
    "    # Create Website nodes with relationships\n",
    "    print(\"\\n5. Creating Website nodes and relationships...\")\n",
    "    for domain, website_data in tqdm(all_websites.items(), desc=\"Websites\"):\n",
    "        # Create Website node\n",
    "        website_query = \"\"\"\n",
    "        CREATE (w:Website {\n",
    "            domain: $domain,\n",
    "            url: $url,\n",
    "            visited_at: datetime()\n",
    "        })\n",
    "        \"\"\"\n",
    "        neo4j_conn.query(website_query, domain=domain, url=website_data['url'])\n",
    "        \n",
    "        # Link User to Website\n",
    "        user_to_website = \"\"\"\n",
    "        MATCH (u:User {user_id: 'user_001'})\n",
    "        MATCH (w:Website {domain: $domain})\n",
    "        CREATE (u)-[:VISITED]->(w)\n",
    "        \"\"\"\n",
    "        neo4j_conn.query(user_to_website, domain=domain)\n",
    "        \n",
    "        # Link Website to Category\n",
    "        cat_name = website_data['category']\n",
    "        cat_id = make_id(cat_name)\n",
    "        website_to_category = \"\"\"\n",
    "        MATCH (w:Website {domain: $domain})\n",
    "        MATCH (c:Category {category_id: $category_id})\n",
    "        MERGE (w)-[:HAS_CATEGORY]->(c)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            neo4j_conn.query(website_to_category, domain=domain, category_id=cat_id)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Link Website to Topic (if topic exists)\n",
    "        if website_data['topic']:\n",
    "            topic_id = f\"web_{make_id(website_data['topic'][:50])}_\"\n",
    "            # Find matching topic\n",
    "            find_topic = \"\"\"\n",
    "            MATCH (t:Topic)\n",
    "            WHERE t.content = $topic_text AND t.source = 'website_extraction'\n",
    "            RETURN t.topic_id AS topic_id\n",
    "            LIMIT 1\n",
    "            \"\"\"\n",
    "            result = neo4j_conn.query(find_topic, topic_text=website_data['topic'])\n",
    "            if result:\n",
    "                website_to_topic = \"\"\"\n",
    "                MATCH (w:Website {domain: $domain})\n",
    "                MATCH (t:Topic {topic_id: $topic_id})\n",
    "                MERGE (w)-[:HAS_TOPIC]->(t)\n",
    "                \"\"\"\n",
    "                neo4j_conn.query(website_to_topic, domain=domain, topic_id=result[0]['topic_id'])\n",
    "        \n",
    "        # Link Website to Entities\n",
    "        for item in website_data['items']:\n",
    "            if item:\n",
    "                entity_id = make_id(item)\n",
    "                website_to_entity = \"\"\"\n",
    "                MATCH (w:Website {domain: $domain})\n",
    "                MATCH (e:Entity {entity_id: $entity_id})\n",
    "                MERGE (w)-[:MENTIONS]->(e)\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    neo4j_conn.query(website_to_entity, domain=domain, entity_id=entity_id)\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    print(f\"  ✓ Created {len(all_websites)} Website nodes with relationships\")\n",
    "    \n",
    "    # Create Topic-Entity relationships based on mentions\n",
    "    print(\"\\n6. Creating Topic-Entity mention relationships...\")\n",
    "    mention_count = 0\n",
    "    for topic_id, topic_data in tqdm(all_topics.items(), desc=\"Mentions\"):\n",
    "        topic_content = topic_data['content'].lower()\n",
    "        for entity_id, entity_data in all_entities.items():\n",
    "            entity_name = entity_data['name'].lower()\n",
    "            # Simple string matching\n",
    "            if len(entity_name) > 2 and entity_name in topic_content:\n",
    "                mention_query = \"\"\"\n",
    "                MATCH (t:Topic {topic_id: $topic_id})\n",
    "                MATCH (e:Entity {entity_id: $entity_id})\n",
    "                MERGE (t)-[:MENTIONS]->(e)\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    neo4j_conn.query(mention_query, topic_id=topic_id, entity_id=entity_id)\n",
    "                    mention_count += 1\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    print(f\"  ✓ Created {mention_count} MENTIONS relationships\")\n",
    "    \n",
    "    print(\"\\n✅ Knowledge graph population complete!\")\n",
    "else:\n",
    "    print(\"✗ Cannot populate: Neo4j connection not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db3033",
   "metadata": {},
   "source": [
    "## 9. Query and Visualize the Unified Knowledge Graph (Optional)\n",
    "\n",
    "\n",
    "Query the unified graph with Categories, Topics, and Entities from both data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc92fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#D733]  _: <CONNECTION> error: Failed to read from defunct connection IPv4Address(('localhost', 7687)) (ResolvedIPv6Address(('::1', 7687, 0, 0))): OSError('No data')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNOWLEDGE GRAPH STATISTICS ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Bolt.__del__ at 0x12c322ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shreyasjagannath/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/io/_bolt.py\", line 200, in __del__\n",
      "    def __del__(self):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "ServiceUnavailable",
     "evalue": "Failed to read from defunct connection IPv4Address(('localhost', 7687)) (ResolvedIPv6Address(('::1', 7687, 0, 0)))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/io/_common.py:53\u001b[39m, in \u001b[36mInbox._buffer_one_chunk\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m chunk_size == \u001b[32m0\u001b[39m:\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# Determine the chunk size and skip noop\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[43mreceive_into_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_socket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     chunk_size = \u001b[38;5;28mself\u001b[39m._buffer.pop_u16()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/io/_common.py:343\u001b[39m, in \u001b[36mreceive_into_buffer\u001b[39m\u001b[34m(sock, buffer, n_bytes)\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    344\u001b[39m buffer.used += n\n",
      "\u001b[31mOSError\u001b[39m: No data",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceUnavailable\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== KNOWLEDGE GRAPH STATISTICS ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m stats_query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33mMATCH (n)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mRETURN \u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m    count(*) as total_nodes,\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m    size(collect(distinct labels(n))) as node_types\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m result = \u001b[43mneo4j_conn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstats_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal nodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtotal_nodes\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mNeo4jConnection.query\u001b[39m\u001b[34m(self, query_str, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_str, **kwargs):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.driver.session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.data()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/work/session.py:320\u001b[39m, in \u001b[36mSession.run\u001b[39m\u001b[34m(self, query, parameters, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m bookmarks = \u001b[38;5;28mself\u001b[39m._get_bookmarks()\n\u001b[32m    319\u001b[39m parameters = \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_result\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpersonated_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_access_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbookmarks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnotifications_min_severity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnotifications_disabled_classifications\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._auto_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/work/result.py:237\u001b[39m, in \u001b[36mResult._run\u001b[39m\u001b[34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m._pull()\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m._connection.send_all()\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/work/result.py:439\u001b[39m, in \u001b[36mResult._attach\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exhausted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    438\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/io/_common.py:192\u001b[39m, in \u001b[36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwargs):\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    194\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio.iscoroutinefunction(\u001b[38;5;28mself\u001b[39m.__on_error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/io/_bolt.py:863\u001b[39m, in \u001b[36mBolt.fetch_message\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    860\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m    862\u001b[39m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m863\u001b[39m tag, fields = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minbox\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhydration_hooks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhydration_hooks\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m res = \u001b[38;5;28mself\u001b[39m._process_message(tag, fields)\n\u001b[32m    867\u001b[39m \u001b[38;5;28mself\u001b[39m.idle_since = monotonic()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/io/_common.py:76\u001b[39m, in \u001b[36mInbox.pop\u001b[39m\u001b[34m(self, hydration_hooks)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, hydration_hooks):\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer_one_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     78\u001b[39m         size, tag = \u001b[38;5;28mself\u001b[39m._unpacker.unpack_structure_header()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/io/_common.py:72\u001b[39m, in \u001b[36mInbox._buffer_one_chunk\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[32m     67\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m,\n\u001b[32m     68\u001b[39m     SocketDeadlineExceededError,\n\u001b[32m     69\u001b[39m     asyncio.CancelledError,\n\u001b[32m     70\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mself\u001b[39m._broken = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[43mUtil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_async_compat/util.py:105\u001b[39m, in \u001b[36mUtil.callback\u001b[39m\u001b[34m(cb, *args, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcallback\u001b[39m(cb, *args, **kwargs):\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(cb):\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/io/_bolt.py:891\u001b[39m, in \u001b[36mBolt._set_defunct_read\u001b[39m\u001b[34m(self, error, silent)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_defunct_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, error=\u001b[38;5;28;01mNone\u001b[39;00m, silent=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    887\u001b[39m     message = (\n\u001b[32m    888\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to read from defunct connection \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    889\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.unresolved_address\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.server_info.address\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    890\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m891\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_defunct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/fabric/.venv/lib/python3.12/site-packages/neo4j/_sync/io/_bolt.py:970\u001b[39m, in \u001b[36mBolt._set_defunct\u001b[39m\u001b[34m(self, message, error, silent)\u001b[39m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m direct_driver:\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m\n\u001b[32m    971\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    972\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(message)\n",
      "\u001b[31mServiceUnavailable\u001b[39m: Failed to read from defunct connection IPv4Address(('localhost', 7687)) (ResolvedIPv6Address(('::1', 7687, 0, 0)))"
     ]
    }
   ],
   "source": [
    "if neo4j_conn:\n",
    "    # Query 1: Get graph statistics\n",
    "    print(\"=== KNOWLEDGE GRAPH STATISTICS ===\\n\")\n",
    "    \n",
    "    stats_query = \"\"\"\n",
    "    MATCH (n)\n",
    "    RETURN \n",
    "        count(*) as total_nodes,\n",
    "        size(collect(distinct labels(n))) as node_types\n",
    "    \"\"\"\n",
    "    result = neo4j_conn.query(stats_query)\n",
    "    if result:\n",
    "        print(f\"Total nodes: {result[0]['total_nodes']}\")\n",
    "    \n",
    "    # Node counts by type\n",
    "    node_type_query = \"\"\"\n",
    "    MATCH (n)\n",
    "    UNWIND labels(n) as label\n",
    "    RETURN label, count(*) as count\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    result = neo4j_conn.query(node_type_query)\n",
    "    print(\"\\nNodes by type:\")\n",
    "    for row in result:\n",
    "        print(f\"  - {row['label']}: {row['count']}\")\n",
    "    \n",
    "    # Relationship statistics\n",
    "    rel_query = \"\"\"\n",
    "    MATCH ()-[r]->()\n",
    "    RETURN type(r) as relationship_type, count(*) as count\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    result = neo4j_conn.query(rel_query)\n",
    "    print(\"\\nRelationships by type:\")\n",
    "    for row in result:\n",
    "        print(f\"  - {row['relationship_type']}: {row['count']}\")\n",
    "    \n",
    "    print(\"\\n✓ Graph statistics retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66015546",
   "metadata": {},
   "outputs": [],
   "source": [
    "if neo4j_conn:\n",
    "    # Query 2: Get most connected entities\n",
    "    print(\"\\n=== TOP ENTITIES BY CONNECTIONS ===\\n\")\n",
    "    \n",
    "    top_entities_query = \"\"\"\n",
    "    MATCH (e:Entity)-[r]->()\n",
    "    RETURN e.name as entity, count(r) as connection_count\n",
    "    ORDER BY connection_count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    result = neo4j_conn.query(top_entities_query)\n",
    "    for row in result:\n",
    "        print(f\"  {row['entity']}: {row['connection_count']} connections\")\n",
    "    \n",
    "    print(\"\\n✓ Top entities retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "if neo4j_conn:\n",
    "    # Query 3: Get most active categories\n",
    "    print(\"\\n=== TOP CATEGORIES BY ACTIVITY ===\\n\")\n",
    "    \n",
    "    top_categories_query = \"\"\"\n",
    "    MATCH (c:Category)\n",
    "    RETURN c.name as category, c.activity_count as activity_count, c.search_count as search_count\n",
    "    ORDER BY c.activity_count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    result = neo4j_conn.query(top_categories_query)\n",
    "    for row in result:\n",
    "        print(f\"  {row['category']}\")\n",
    "        print(f\"    - Activities: {row['activity_count']}, Searches: {row['search_count']}\")\n",
    "    \n",
    "    print(\"\\n✓ Top categories retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if neo4j_conn:\n",
    "    # Query 4: Semantic search using embeddings\n",
    "    print(\"\\n=== SEMANTIC SEARCH EXAMPLE ===\\n\")\n",
    "    \n",
    "    # Get an entity embedding for similarity search\n",
    "    query_text = \"technology artificial intelligence machine learning\"\n",
    "    query_embedding = get_embedding(query_text)\n",
    "    \n",
    "    print(f\"Query: '{query_text}'\")\n",
    "    print(\"\\nFinding similar entities...\")\n",
    "    \n",
    "    # Get all entities and their embeddings\n",
    "    entities_query = \"\"\"\n",
    "    MATCH (e:Entity)\n",
    "    WHERE e.embedding IS NOT NULL\n",
    "    RETURN e.name as name, e.embedding as embedding\n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "    results = neo4j_conn.query(entities_query)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = []\n",
    "    for result in results:\n",
    "        entity_embedding = np.array(result['embedding'])\n",
    "        query_vec = np.array(query_embedding).reshape(1, -1)\n",
    "        entity_vec = entity_embedding.reshape(1, -1)\n",
    "        similarity = cosine_similarity(query_vec, entity_vec)[0][0]\n",
    "        similarities.append({\n",
    "            'entity': result['name'],\n",
    "            'similarity': float(similarity)\n",
    "        })\n",
    "    \n",
    "    # Sort by similarity\n",
    "    similarities = sorted(similarities, key=lambda x: x['similarity'], reverse=True)\n",
    "    \n",
    "    for i, result in enumerate(similarities[:5]):\n",
    "        print(f\"  {i+1}. {result['entity']}: {result['similarity']:.3f}\")\n",
    "    \n",
    "    print(\"\\n✓ Semantic search completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if neo4j_conn:\n",
    "    # Query 5: Get subgraph around a category\n",
    "    print(\"\\n=== CATEGORY SUBGRAPH ===\\n\")\n",
    "    \n",
    "    category_subgraph_query = \"\"\"\n",
    "    MATCH (c:Category {name: \"Technology & Innovation\"})\n",
    "    MATCH (t:Topic)-[:BELONGS_TO]->(c)\n",
    "    MATCH (t)-[:MENTIONS]->(e:Entity)\n",
    "    RETURN \n",
    "        c.name as category,\n",
    "        count(DISTINCT t) as topic_count,\n",
    "        count(DISTINCT e) as entity_count,\n",
    "        collect(DISTINCT e.name)[0..5] as sample_entities\n",
    "    \"\"\"\n",
    "    result = neo4j_conn.query(category_subgraph_query)\n",
    "    if result:\n",
    "        row = result[0]\n",
    "        print(f\"Category: {row['category']}\")\n",
    "        print(f\"Topics: {row['topic_count']}\")\n",
    "        print(f\"Entities: {row['entity_count']}\")\n",
    "        print(f\"Sample entities: {row['sample_entities']}\")\n",
    "    \n",
    "    print(\"\\n✓ Category subgraph retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ef70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Create a sample network graph\n",
    "if neo4j_conn:\n",
    "    print(\"\\n=== CREATING NETWORK VISUALIZATION ===\\n\")\n",
    "    \n",
    "    # Build a networkx graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add sample nodes and edges from the database\n",
    "    sample_query = \"\"\"\n",
    "    MATCH (n1)-[r]->(n2)\n",
    "    WHERE labels(n1)[0] IN ['Category', 'Topic', 'Entity']\n",
    "    RETURN \n",
    "        labels(n1)[0] as label1,\n",
    "        coalesce(n1.name, n1.topic_id, n1.entity_id) as node1,\n",
    "        labels(n2)[0] as label2,\n",
    "        coalesce(n2.name, n2.topic_id, n2.entity_id) as node2,\n",
    "        type(r) as relationship_type\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "    \n",
    "    results = neo4j_conn.query(sample_query)\n",
    "    \n",
    "    # Build graph\n",
    "    for result in results:\n",
    "        node1 = result['node1']\n",
    "        node2 = result['node2']\n",
    "        label1 = result['label1']\n",
    "        label2 = result['label2']\n",
    "        \n",
    "        G.add_node(node1, node_type=label1)\n",
    "        G.add_node(node2, node_type=label2)\n",
    "        G.add_edge(node1, node2, relationship=result['relationship_type'])\n",
    "    \n",
    "    print(f\"Graph created with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    # Use spring layout for visualization\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "    \n",
    "    # Color nodes by type\n",
    "    node_colors = []\n",
    "    color_map = {'Category': '#FF6B6B', 'Topic': '#4ECDC4', 'Entity': '#45B7D1'}\n",
    "    for node in G.nodes():\n",
    "        node_type = G.nodes[node].get('node_type', 'Unknown')\n",
    "        node_colors.append(color_map.get(node_type, '#95E1D3'))\n",
    "    \n",
    "    # Draw network\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=800, ax=ax, alpha=0.9)\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='gray', arrows=True, \n",
    "                          arrowsize=20, arrowstyle='->', ax=ax, \n",
    "                          connectionstyle='arc3,rad=0.1', alpha=0.5, width=1.5)\n",
    "    \n",
    "    # Draw labels for high-degree nodes only\n",
    "    high_degree_nodes = {node: node for node, degree in dict(G.degree()).items() if degree > 2}\n",
    "    nx.draw_networkx_labels(G, pos, labels=high_degree_nodes, font_size=8, ax=ax)\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#FF6B6B', label='Category'),\n",
    "        Patch(facecolor='#4ECDC4', label='Topic'),\n",
    "        Patch(facecolor='#45B7D1', label='Entity')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper left')\n",
    "    \n",
    "    ax.set_title('Knowledge Graph Network Visualization\\n(Sample Subgraph)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Visualization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and utility functions\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"KNOWLEDGE GRAPH CONSTRUCTION COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define utility functions for future use\n",
    "def search_by_similarity(query_text, node_type='Entity', limit=5):\n",
    "    \"\"\"\n",
    "    Semantic search in the knowledge graph\n",
    "    \"\"\"\n",
    "    if not neo4j_conn:\n",
    "        print(\"Neo4j connection not available\")\n",
    "        return []\n",
    "    \n",
    "    query_embedding = get_embedding(query_text)\n",
    "    \n",
    "    cypher_query = f\"\"\"\n",
    "    MATCH (n:{node_type})\n",
    "    WHERE n.embedding IS NOT NULL\n",
    "    RETURN \n",
    "        labels(n)[0] as node_type,\n",
    "        coalesce(n.name, n.topic_id, n.entity_id) as node_id,\n",
    "        n.embedding as embedding\n",
    "    LIMIT {limit * 3}\n",
    "    \"\"\"\n",
    "    \n",
    "    results = neo4j_conn.query(cypher_query)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = []\n",
    "    for result in results:\n",
    "        node_embedding = np.array(result['embedding'])\n",
    "        query_vec = np.array(query_embedding).reshape(1, -1)\n",
    "        node_vec = node_embedding.reshape(1, -1)\n",
    "        similarity = cosine_similarity(query_vec, node_vec)[0][0]\n",
    "        similarities.append({\n",
    "            'node_id': result['node_id'],\n",
    "            'node_type': result['node_type'],\n",
    "            'similarity': float(similarity)\n",
    "        })\n",
    "    \n",
    "    # Sort and return top results\n",
    "    similarities = sorted(similarities, key=lambda x: x['similarity'], reverse=True)\n",
    "    return similarities[:limit]\n",
    "\n",
    "def get_entity_connections(entity_name):\n",
    "    \"\"\"Get all connections for an entity\"\"\"\n",
    "    if not neo4j_conn:\n",
    "        print(\"Neo4j connection not available\")\n",
    "        return {}\n",
    "    \n",
    "    query = \"\"\"\n",
    "    MATCH (e:Entity {name: $name})\n",
    "    OPTIONAL MATCH (e)<-[:MENTIONS]-(t:Topic)\n",
    "    OPTIONAL MATCH (e)-[:CO_OCCURS_WITH]->(other:Entity)\n",
    "    RETURN \n",
    "        e.name as entity,\n",
    "        count(DISTINCT t) as topic_mentions,\n",
    "        collect(DISTINCT other.name) as related_entities\n",
    "    \"\"\"\n",
    "    \n",
    "    result = neo4j_conn.query(query, name=entity_name)\n",
    "    return result[0] if result else {}\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n📊 Available Functions:\")\n",
    "print(\"  - search_by_similarity(query_text, node_type='Entity', limit=5)\")\n",
    "print(\"  - get_entity_connections(entity_name)\")\n",
    "print(\"  - neo4j_conn.query(cypher_query)\")\n",
    "\n",
    "print(\"\\n✨ Knowledge graph ready for exploration!\")\n",
    "print(f\"\\nAccess at: {NEO4J_URI}\")\n",
    "print(f\"Login: {NEO4J_USER} / ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241eb5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_by_similarity(\"blackstone\")  # Example function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43412402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for similar topics by semantic similarity\n",
    "print(\"\\n=== SEMANTIC TOPIC SEARCH ===\\n\")\n",
    "\n",
    "# Define a search query\n",
    "topic_query_text = \"machine learning deep learning neural networks\"\n",
    "print(f\"Query: '{topic_query_text}'\")\n",
    "print(\"Finding similar topics...\\n\")\n",
    "\n",
    "# Use the search function but for Topics instead of Entities\n",
    "topic_results = search_by_similarity(topic_query_text, node_type='Topic', limit=10)\n",
    "\n",
    "print(\"Top 10 similar topics:\")\n",
    "for i, result in enumerate(topic_results, 1):\n",
    "    print(f\"{i}. {result['node_id']}: {result['similarity']:.4f}\")\n",
    "\n",
    "# You can also search with other queries:\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Another example - searching for finance-related topics:\")\n",
    "finance_results = search_by_similarity(\"stock market investment finance banking\", node_type='Topic', limit=5)\n",
    "for i, result in enumerate(finance_results, 1):\n",
    "    print(f\"{i}. {result['node_id']}: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep dive: Get detailed topic information with similarity\n",
    "print(\"\\n=== DETAILED TOPIC SIMILARITY ANALYSIS ===\\n\")\n",
    "\n",
    "# Search for topics and get their full details\n",
    "def search_topics_detailed(query_text, limit=5):\n",
    "    \"\"\"Search for topics and return detailed information including content\"\"\"\n",
    "    \n",
    "    # Get top similar topics\n",
    "    results = search_by_similarity(query_text, node_type='Topic', limit=limit)\n",
    "    \n",
    "    # Fetch detailed information for each topic\n",
    "    detailed_results = []\n",
    "    for result in results:\n",
    "        topic_query = \"\"\"\n",
    "        MATCH (t:Topic {topic_id: $topic_id})\n",
    "        OPTIONAL MATCH (t)-[:BELONGS_TO]->(c:Category)\n",
    "        OPTIONAL MATCH (t)-[:MENTIONS]->(e:Entity)\n",
    "        RETURN \n",
    "            t.topic_id as topic_id,\n",
    "            t.content as content,\n",
    "            c.name as category,\n",
    "            count(DISTINCT e) as entity_count,\n",
    "            collect(DISTINCT e.name) as entities\n",
    "        \"\"\"\n",
    "        try:\n",
    "            topic_details = neo4j_conn.query(topic_query, topic_id=result['node_id'])\n",
    "            if topic_details:\n",
    "                detail = topic_details[0]\n",
    "                detail['similarity'] = result['similarity']\n",
    "                detailed_results.append(detail)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return detailed_results\n",
    "\n",
    "# Example usage\n",
    "search_query = \"python programming software development\"\n",
    "detailed_topics = search_topics_detailed(search_query, limit=5)\n",
    "\n",
    "print(f\"Query: '{search_query}'\\n\")\n",
    "for i, topic in enumerate(detailed_topics, 1):\n",
    "    print(f\"{i}. {topic['topic_id']} (Similarity: {topic['similarity']:.4f})\")\n",
    "    print(f\"   Content: {topic['content'][:80]}...\")\n",
    "    print(f\"   Category: {topic['category']}\")\n",
    "    print(f\"   Entities mentioned: {topic['entity_count']}\")\n",
    "    if topic['entities']:\n",
    "        print(f\"   Entities: {', '.join(topic['entities'][:3])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c49a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 similar topics with complete details\n",
    "print(\"\\n=== TOP 5 SIMILAR TOPICS WITH FULL DETAILS ===\\n\")\n",
    "\n",
    "query_text = \"artificial intelligence machine learning\"\n",
    "# query_text = \"bollywood\"\n",
    "\n",
    "print(f\"Search Query: '{query_text}'\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get top 5 similar topics\n",
    "top_5_topics = search_topics_detailed(query_text, limit=5)\n",
    "\n",
    "for idx, topic in enumerate(top_5_topics, 1):\n",
    "    print(f\"\\n#{idx} - Topic ID: {topic['topic_id']}\")\n",
    "    print(f\"    Similarity Score: {topic['similarity']:.4f}\")\n",
    "    print(f\"    Category: {topic['category']}\")\n",
    "    print(f\"    Content: {topic['content']}\")\n",
    "    if topic['entities'] and len(topic['entities']) > 0:\n",
    "        print(f\"    Related Entities: {', '.join(topic['entities'])}\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "print(\"\\n✓ Top 5 similar topics retrieved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the unified categories from both data sources\n",
    "print(\"=== UNIFIED CATEGORIES FROM BOTH DATA SOURCES ===\\n\")\n",
    "for i, (cat_id, cat_data) in enumerate(all_categories.items(), 1):\n",
    "    print(f\"{i}. {cat_data['name']}\")\n",
    "    print(f\"   - Source: {cat_data['source']}\")\n",
    "    print(f\"   - Activities: {cat_data.get('activity_count', 0)}\")\n",
    "    print(f\"   - Searches: {cat_data.get('search_count', 0)}\")\n",
    "    # Count topics for this category\n",
    "    topic_count = sum(1 for t in all_topics.values() if t.get('category') == cat_data['name'])\n",
    "    print(f\"   - Topics: {topic_count}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

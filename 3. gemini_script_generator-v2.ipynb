{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a973554",
   "metadata": {},
   "source": [
    "# Gemini 3 Script Generator with Knowledge Graph\n",
    "\n",
    "This notebook demonstrates how to use the Gemini 3 API (via `google-genai`) to generate scripts based on user input, enriched with context from a Neo4j Knowledge Graph.\n",
    "\n",
    "## Prerequisites\n",
    "- Neo4j Database running (with the Fabric Knowledge Graph loaded)\n",
    "- Google Gemini API Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install -q -r requirements.txt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803336b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .env from: /Users/shreyasjagannath/dev/fabric/onfabric-data-science-interview/.env\n",
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from neo4j import GraphDatabase, basic_auth\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Load environment variables\n",
    "# Try to find .env file explicitly if not found automatically\n",
    "dotenv_path = find_dotenv()\n",
    "if dotenv_path:\n",
    "    print(f\"Loading .env from: {dotenv_path}\")\n",
    "    load_dotenv(dotenv_path, override=True)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è .env file not found. Please ensure it exists in the project root.\")\n",
    "    # Fallback: try loading from current directory\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901980c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Successfully connected to Neo4j\n"
     ]
    }
   ],
   "source": [
    "# Neo4j Configuration\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"password\"\n",
    "\n",
    "class Neo4jConnection:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = None\n",
    "        try:\n",
    "            self.driver = GraphDatabase.driver(uri, auth=basic_auth(user, password))\n",
    "            with self.driver.session() as session:\n",
    "                session.run(\"RETURN 1\")\n",
    "                print(\"‚úì Successfully connected to Neo4j\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Connection failed: {e}\")\n",
    "            \n",
    "        \n",
    "    def close(self):\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "    \n",
    "    def query(self, query_str, **kwargs):\n",
    "        with self.driver.session() as session:\n",
    "            return session.run(query_str, **kwargs).data()\n",
    "\n",
    "# Initialize connection\n",
    "neo4j_conn = Neo4jConnection(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38cfa136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini client initialized.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gemini Client\n",
    "# Ensure you have GOOGLE_API_KEY or GEMINI_API_KEY in your .env file\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\") or os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"‚ö†Ô∏è GOOGLE_API_KEY or GEMINI_API_KEY not found in environment variables.\")\n",
    "    print(\"Gemini features will be disabled until a valid key is provided.\")\n",
    "    client = None\n",
    "else:\n",
    "    client = genai.Client(api_key=api_key)\n",
    "    print(\"Gemini client initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2053f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model (this may take a moment)...\n",
      "‚úì Embedding model loaded.\n",
      "‚úì Embedding model loaded.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Embedding Model\n",
    "print(\"Loading embedding model (this may take a moment)...\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"‚úì Embedding model loaded.\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generate embedding for text using sentence transformers.\"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return None\n",
    "    try:\n",
    "        clean_text = text.strip()[:512]\n",
    "        embedding = embedding_model.encode(clean_text)\n",
    "        # Convert to list of Python floats (not numpy types)\n",
    "        return [float(x) for x in embedding.tolist()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error embedding text: {e}\")\n",
    "        return None\n",
    "\n",
    "def search_knowledge_graph(query_text, node_types=['Topic', 'Entity'], limit=10):\n",
    "    \"\"\"\n",
    "    Search the knowledge graph using Neo4j vector indexes for semantic similarity.\n",
    "    \n",
    "    Args:\n",
    "        query_text: Natural language query\n",
    "        node_types: List of node types to search (['Topic', 'Entity', 'Category'])\n",
    "        limit: Number of results to return per node type\n",
    "    \n",
    "    Returns:\n",
    "        List of relevant items with type, content, and similarity score\n",
    "    \"\"\"\n",
    "    if not neo4j_conn:\n",
    "        print(\"‚ö†Ô∏è Neo4j connection not available\")\n",
    "        return []\n",
    "    \n",
    "    query_embedding = get_embedding(query_text)\n",
    "    if query_embedding is None:\n",
    "        print(\"‚ö†Ô∏è Could not generate embedding for query\")\n",
    "        return []\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Map node types to their vector indexes\n",
    "    index_map = {\n",
    "        'Entity': 'entity_embedding_idx',\n",
    "        'Topic': 'topic_embedding_idx',\n",
    "        'Category': 'category_embedding_idx'\n",
    "    }\n",
    "    \n",
    "    # Query each node type using its vector index\n",
    "    for node_type in node_types:\n",
    "        if node_type not in index_map:\n",
    "            continue\n",
    "            \n",
    "        index_name = index_map[node_type]\n",
    "        \n",
    "        # Use Neo4j vector index for efficient semantic search\n",
    "        vector_query = f\"\"\"\n",
    "        CALL db.index.vector.queryNodes('{index_name}', $k, $embedding)\n",
    "        YIELD node, score\n",
    "        RETURN \n",
    "            labels(node)[0] as node_type,\n",
    "            coalesce(node.name, node.content) as content,\n",
    "            score as similarity\n",
    "        ORDER BY similarity DESC\n",
    "        LIMIT $limit\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            results = neo4j_conn.query(\n",
    "                vector_query,\n",
    "                embedding=query_embedding,\n",
    "                k=limit * 2,  # Query more, filter to limit\n",
    "                limit=limit\n",
    "            )\n",
    "            all_results.extend(results)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error querying {node_type}: {e}\")\n",
    "    \n",
    "    # Sort all results by similarity and return top results\n",
    "    all_results = sorted(all_results, key=lambda x: x['similarity'], reverse=True)\n",
    "    \n",
    "    # Format results for consistency\n",
    "    formatted_results = []\n",
    "    for result in all_results[:limit]:\n",
    "        formatted_results.append({\n",
    "            'type': result['node_type'],\n",
    "            'content': result['content'],\n",
    "            'similarity': float(result['similarity'])\n",
    "        })\n",
    "    \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e06ff4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Generator function defined with vector search integration.\n"
     ]
    }
   ],
   "source": [
    "def generate_script_with_context(user_request):\n",
    "    \"\"\"\n",
    "    Generates a video/movie script based on user request, using Knowledge Graph context.\n",
    "    Uses Neo4j vector indexes for efficient semantic search.\n",
    "    \"\"\"\n",
    "    print(f\"üîç Analyzing request: '{user_request}'\")\n",
    "    \n",
    "    # 1. Get Context from Knowledge Graph using vector search\n",
    "    print(\"   Querying Knowledge Graph with vector indexes...\")\n",
    "    \n",
    "    # Search both Topics and Entities for comprehensive context\n",
    "    kg_results = search_knowledge_graph(\n",
    "        user_request, \n",
    "        node_types=['Topic', 'Entity', 'Category'],\n",
    "        limit=15\n",
    "    )\n",
    "    \n",
    "    context_str = \"\"\n",
    "    if kg_results:\n",
    "        print(f\"\\n   --- Found {len(kg_results)} Relevant Items ---\")\n",
    "        \n",
    "        # Group results by type for better context organization\n",
    "        topics = [r for r in kg_results if r['type'] == 'Topic']\n",
    "        entities = [r for r in kg_results if r['type'] == 'Entity']\n",
    "        categories = [r for r in kg_results if r['type'] == 'Category']\n",
    "        \n",
    "        context_str = \"Relevant Context from Knowledge Graph (User's Interests & Activity):\\n\\n\"\n",
    "        \n",
    "        if categories:\n",
    "            context_str += \"User Interest Categories:\\n\"\n",
    "            for cat in categories[:3]:\n",
    "                context_str += f\"  - {cat['content']} (relevance: {cat['similarity']:.2f})\\n\"\n",
    "                print(f\"   [Category] {cat['content']} (similarity: {cat['similarity']:.3f})\")\n",
    "            context_str += \"\\n\"\n",
    "        \n",
    "        if topics:\n",
    "            context_str += \"Related Topics from User Activity:\\n\"\n",
    "            for topic in topics[:5]:\n",
    "                context_str += f\"  - {topic['content']} (relevance: {topic['similarity']:.2f})\\n\"\n",
    "                print(f\"   [Topic] {topic['content'][:60]}... (similarity: {topic['similarity']:.3f})\")\n",
    "            context_str += \"\\n\"\n",
    "        \n",
    "        if entities:\n",
    "            context_str += \"Specific Items/Brands User Has Engaged With:\\n\"\n",
    "            for entity in entities[:7]:\n",
    "                context_str += f\"  - {entity['content']} (relevance: {entity['similarity']:.2f})\\n\"\n",
    "                print(f\"   [Entity] {entity['content']} (similarity: {entity['similarity']:.3f})\")\n",
    "        \n",
    "        print(\"   \" + \"-\"*50)\n",
    "        \n",
    "    else:\n",
    "        context_str = \"No specific context found in Knowledge Graph.\"\n",
    "        print(\"   ‚ö†Ô∏è No relevant context found\")\n",
    "        \n",
    "    print(f\"\\n   ‚úì Retrieved {len(kg_results)} relevant items from knowledge graph\")\n",
    "    \n",
    "    # 2. Construct Enhanced Prompt for Gemini\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert creative writer and video scriptwriter.\n",
    "    \n",
    "    User Request: {user_request}\n",
    "    \n",
    "    {context_str}\n",
    "    \n",
    "    Task: Create a creative video/movie script that addresses the user's request, personalized to their interests.\n",
    "    \n",
    "    CRITICAL CONSTRAINT: The video must be exactly 8 seconds long. The storyline must be concise, impactful, and complete within this short duration.\n",
    "    \n",
    "    Guidelines:\n",
    "    1. **Personalization**: Use the knowledge graph context above to tailor the script to the user's specific interests, \n",
    "       activities, and preferences. Reference relevant topics, categories, and items they've engaged with.\n",
    "    2. **Structure**: Format the script with:\n",
    "       - **Title**: Catchy and relevant title\n",
    "       - **Logline**: A one-sentence summary of the short storyline.\n",
    "       - **Scene/Setting Description**: Clear visual setting.\n",
    "       - **Action/Visuals**: Detailed visual cues for the 8-second sequence.\n",
    "       - **Audio/Voiceover**: Minimal dialogue or voiceover, strictly timed (0:00-0:08).\n",
    "    3. **Storyline**: Create a micro-narrative with a clear beginning, middle, and end, even within 8 seconds.\n",
    "    4. **Tone**: Match the tone to the user's request and their interest profile.\n",
    "    5. **Length**: Keep the script concise. Focus on visual storytelling.\n",
    "    \n",
    "    Output the script in clear Markdown format.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 3. Call Gemini API\n",
    "    print(\"   Generating personalized script with Gemini...\")\n",
    "    \n",
    "    if client is None:\n",
    "        return \"‚ùå Gemini Client not initialized. Please provide GOOGLE_API_KEY.\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-3-pro-preview\",\n",
    "            contents=prompt\n",
    "        )\n",
    "        print(\"   ‚úì Script generated successfully\\n\")\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error generating content: {e}\"\n",
    "\n",
    "print(\"‚úì Generator function defined with vector search integration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0357eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def create_video_from_script(script_text):\n",
    "    \"\"\"\n",
    "    Extracts a visual prompt from the script and generates a video using Veo 3.\n",
    "    \"\"\"\n",
    "    if not script_text:\n",
    "        print(\"‚ùå No script provided.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # 1. Generate Video with Veo 3\n",
    "    print(f\"\\nüé• Generating video with Veo...\")\n",
    "    \n",
    "    # Initialize v1alpha client for Veo\n",
    "    try:\n",
    "        from google.genai.types import HttpOptions\n",
    "        alpha_client = genai.Client(\n",
    "            api_key=api_key,\n",
    "            http_options=HttpOptions(api_version='v1alpha')\n",
    "        )\n",
    "        print(\"   Initialized v1alpha client for Veo.\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Could not initialize v1alpha client ({e}), using default.\")\n",
    "        alpha_client = client\n",
    "\n",
    "    # model_name = \"veo-3.1-generate-preview\"\n",
    "    model_name = \"veo-3.1-fast-generate-preview\"\n",
    "    \n",
    "    print(f\"   Attempting with model: {model_name}...\")\n",
    "\n",
    "    try:\n",
    "        # Start the video generation operation\n",
    "        operation = alpha_client.models.generate_videos(\n",
    "            model=model_name,\n",
    "            prompt=script_text,\n",
    "        )\n",
    "        \n",
    "        print(\"   Operation started. Waiting for video generation to complete...\")\n",
    "        \n",
    "        # Poll the operation status until the video is ready.\n",
    "        while not operation.done:\n",
    "            print(\"   ...still processing...\")\n",
    "            time.sleep(10)\n",
    "            operation = alpha_client.operations.get(operation)\n",
    "            \n",
    "        if operation.result:\n",
    "             # Download the generated video.\n",
    "            generated_video = operation.result.generated_videos[0]\n",
    "            \n",
    "            # Create unique filename with timestamp in videos folder\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_dir = \"videos\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            output_file = os.path.join(output_dir, f\"generated_video_{timestamp}.mp4\")\n",
    "            \n",
    "            # Check if we have a URI to download from\n",
    "            video_uri = getattr(generated_video.video, 'uri', None)\n",
    "            \n",
    "            if video_uri:\n",
    "                # Append API key for authentication\n",
    "                authenticated_uri = f\"{video_uri}&key={api_key}\"\n",
    "                print(f\"   Downloading video from authenticated URI...\")\n",
    "                \n",
    "                try:\n",
    "                    response = requests.get(authenticated_uri, stream=True)\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                    with open(output_file, \"wb\") as f:\n",
    "                        for chunk in response.iter_content(chunk_size=8192):\n",
    "                            if chunk:\n",
    "                                f.write(chunk)\n",
    "                    print(f\"‚úì Video saved successfully to {output_file}\")\n",
    "                except Exception as download_err:\n",
    "                    print(f\"   ‚ùå Failed to download video from URI: {download_err}\")\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è No URI found in generated video object. Trying fallback download...\")\n",
    "                # Fallback: try using the client's file download if URI is missing but name exists\n",
    "                try:\n",
    "                    video_content = alpha_client.files.content(file_name=generated_video.video.name)\n",
    "                    with open(output_file, \"wb\") as f:\n",
    "                        f.write(video_content)\n",
    "                    print(f\"‚úì Video saved successfully to {output_file}\")\n",
    "                except Exception as e:\n",
    "                     print(f\"   ‚ùå Fallback download failed: {e}\")\n",
    "                     print(f\"   Debug info - generated_video.video: {generated_video.video}\")\n",
    "\n",
    "        else:\n",
    "            print(\"   ‚ùå Operation completed but no result returned.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed with {model_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a24c844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing request: 'travel to paradise'\n",
      "   Querying Knowledge Graph with vector indexes...\n",
      "\n",
      "   --- Found 15 Relevant Items ---\n",
      "   [Topic] To Paradise review... (similarity: 0.879)\n",
      "   [Topic] shopping paradise... (similarity: 0.842)\n",
      "   [Topic] Travel destination... (similarity: 0.775)\n",
      "   [Topic] Travel destination... (similarity: 0.775)\n",
      "   [Topic] Travel destination... (similarity: 0.775)\n",
      "   [Entity] To Paradise (similarity: 0.936)\n",
      "   [Entity] Dayal Paradise (similarity: 0.837)\n",
      "   [Entity] Paradise Road (similarity: 0.831)\n",
      "   [Entity] travel (similarity: 0.787)\n",
      "   --------------------------------------------------\n",
      "\n",
      "   ‚úì Retrieved 15 relevant items from knowledge graph\n",
      "   Generating personalized script with Gemini...\n",
      "   ‚úì Script generated successfully\n",
      "\n",
      "\n",
      "========================================\n",
      "GENERATED SCRIPT\n",
      "========================================\n",
      "\n",
      "Here is a personalized creative video script tailored to your specific interests in literature, luxury shopping, and travel destinations.\n",
      "\n",
      "**Title:** Pages to Places\n",
      "**Logline:** A seamless transition from reading the novel *To Paradise* to experiencing the real-world luxury of Paradise Road and Dayal Paradise.\n",
      "\n",
      "***\n",
      "\n",
      "**SCENE START**\n",
      "\n",
      "**0:00 - 0:02**\n",
      "**Visual:** Close-up of hands holding the book **\"To Paradise\"**. The cover fills the frame. Suddenly, the book is lowered quickly by the user.\n",
      "**Audio:** (Sound effect) Loud, crisp *PAGE TURN* sound morphing into a *WHOOSH*.\n",
      "\n",
      "**0:02 - 0:05**\n",
      "**Visual:** POV shot walking down **Paradise Road**. The user's hand enters the frame holding luxury **shopping bags**. The sun is bright, hitting the cobblestones.\n",
      "**Audio:** (Sound effect) Bustling street ambience mixed with the *clink* of ceramic goods.\n",
      "\n",
      "**0:05 - 0:08**\n",
      "**Visual:** Quick cut to a serene hotel balcony (referencing **Dayal Paradise**). The user clinks a glass against the sunset. Text overlay appears rapidly: **\"Book Your Paradise.\"**\n",
      "**Audio:** (Voiceover - Calm, whispery): \"From fiction... to reality.\"\n",
      "\n",
      "**SCENE END**\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "user_request = \"travel to paradise\"\n",
    "script = generate_script_with_context(user_request)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40 + \"\\nGENERATED SCRIPT\\n\" + \"=\"*40 + \"\\n\")\n",
    "print(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f135c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé• Generating video with Veo...\n",
      "   Initialized v1alpha client for Veo.\n",
      "   Attempting with model: veo-3.1-fast-generate-preview...\n",
      "   Operation started. Waiting for video generation to complete...\n",
      "   ...still processing...\n",
      "   ...still processing...\n",
      "   ...still processing...\n",
      "   ...still processing...\n",
      "   ...still processing...\n",
      "   ...still processing...\n",
      "   Downloading video from authenticated URI...\n",
      "‚úì Video saved successfully to videos/generated_video_20251214_184943.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run the video generation\n",
    "create_video_from_script(script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b2371",
   "metadata": {},
   "source": [
    "### List of Video Generation Models\n",
    "- models/veo-2.0-generate-001\n",
    "- models/veo-3.0-generate-001\n",
    "- models/veo-3.0-fast-generate-001\n",
    "- models/veo-3.1-generate-preview\n",
    "- models/veo-3.1-fast-generate-preview\n",
    "\n",
    "### List of Gemini Text Models\n",
    "\n",
    " - models/gemini-2.5-flash\n",
    " - models/gemini-2.5-pro\n",
    " - models/gemini-2.0-flash-exp\n",
    " - models/gemini-2.0-flash\n",
    " - models/gemini-2.0-flash-001\n",
    " - models/gemini-2.0-flash-lite-001\n",
    " - models/gemini-2.0-flash-lite\n",
    " - models/gemini-2.0-flash-lite-preview-02-05\n",
    " - models/gemini-2.0-flash-lite-preview\n",
    " - models/gemini-exp-1206\n",
    " - models/gemini-2.5-flash-preview-tts\n",
    " - models/gemini-2.5-pro-preview-tts\n",
    " - models/gemma-3-1b-it\n",
    " - models/gemma-3-4b-it\n",
    " - models/gemma-3-12b-it\n",
    " - models/gemma-3-27b-it\n",
    " - models/gemma-3n-e4b-it\n",
    " - models/gemma-3n-e2b-it\n",
    " - models/gemini-flash-latest\n",
    " - models/gemini-flash-lite-latest\n",
    " - models/gemini-pro-latest\n",
    " - models/gemini-2.5-flash-lite\n",
    " - models/gemini-2.5-flash-image-preview\n",
    " - models/gemini-2.5-flash-image\n",
    " - models/gemini-2.5-flash-preview-09-2025\n",
    " - models/gemini-2.5-flash-lite-preview-09-2025\n",
    " - models/gemini-3-pro-preview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
